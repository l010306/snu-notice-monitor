"""
SNUå…¬å‘Šç›‘æ§ç³»ç»Ÿä¼˜åŒ–ç‰ˆ
ç”¨äºç›‘æ§é¦–å°”å¤§å­¦å®˜ç½‘å…¬å‘Šï¼Œå‘ç°æ–°å…¬å‘Šæ—¶å‘é€é‚®ä»¶é€šçŸ¥
"""
import requests
from bs4 import BeautifulSoup
import json
import smtplib
from email.mime.text import MIMEText
from email.header import Header
import logging
import time
import argparse
from datetime import datetime
from snu_config import Config

# é…ç½®æ—¥å¿—
Config.ensure_dirs()
handlers = []
if Config.LOG_TO_FILE:
    handlers.append(logging.FileHandler(Config.get_log_file(), encoding='utf-8'))
if Config.LOG_TO_CONSOLE:
    handlers.append(logging.StreamHandler())

logging.basicConfig(
    level=getattr(logging, Config.LOG_LEVEL),
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=handlers
)
logger = logging.getLogger(__name__)


class SNUNotifier:
    """SNUå…¬å‘Šç›‘æ§ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç›‘æ§å™¨"""
        logger.info("=" * 60)
        logger.info("SNUå…¬å‘Šç›‘æ§ç³»ç»Ÿå¯åŠ¨")
        logger.info("=" * 60)
        
        # éªŒè¯é…ç½®
        try:
            Config.validate_email_config()
            logger.info("âœ“ é‚®ä»¶é…ç½®éªŒè¯é€šè¿‡")
        except ValueError as e:
            logger.error(str(e))
            raise
        
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
    
    def _fetch_with_retry(self, url, max_retries=None):
        """
        å¸¦é‡è¯•æœºåˆ¶çš„HTTPè¯·æ±‚
        
        Args:
            url: è¯·æ±‚URL
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
            
        Returns:
            Responseå¯¹è±¡ï¼Œå¤±è´¥è¿”å›None
        """
        max_retries = max_retries or Config.MAX_RETRIES
        
        for attempt in range(max_retries):
            try:
                logger.debug(f"æ­£åœ¨è¯·æ±‚: {url} (å°è¯• {attempt + 1}/{max_retries})")
                response = requests.get(
                    url,
                    headers=self.headers,
                    timeout=Config.REQUEST_TIMEOUT
                )
                response.raise_for_status()
                response.encoding = 'utf-8'
                return response
                
            except requests.RequestException as e:
                logger.warning(f"è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                
                if attempt < max_retries - 1:
                    delay = Config.RETRY_DELAY * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                    logger.info(f"ç­‰å¾… {delay} ç§’åé‡è¯•...")
                    time.sleep(delay)
                else:
                    logger.error(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒè¯·æ±‚: {url}")
                    return None
        
        return None
    
    def _validate_announcement(self, title, url):
        """
        éªŒè¯å…¬å‘Šæ•°æ®æœ‰æ•ˆæ€§
        
        Args:
            title: å…¬å‘Šæ ‡é¢˜
            url: å…¬å‘Šé“¾æ¥
            
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        if not title or not url:
            logger.debug("æ ‡é¢˜æˆ–URLä¸ºç©º")
            return False
        
        title = title.strip()
        
        # æ£€æŸ¥æ ‡é¢˜é•¿åº¦
        if len(title) < Config.MIN_TITLE_LENGTH:
            logger.debug(f"æ ‡é¢˜è¿‡çŸ­: {title}")
            return False
        
        if len(title) > Config.MAX_TITLE_LENGTH:
            logger.warning(f"æ ‡é¢˜è¿‡é•¿ï¼Œå¯èƒ½æœ‰è¯¯: {title[:50]}...")
            return False
        
        # æ£€æŸ¥URLæ ¼å¼
        if not url.startswith('http'):
            logger.debug(f"URLæ ¼å¼é”™è¯¯: {url}")
            return False
        
        return True
    
    def get_announcements(self):
        """
        æŠ“å–æ‰€æœ‰ç›®æ ‡ç½‘ç«™çš„å…¬å‘Š
        
        Returns:
            å­—å…¸ï¼Œæ ¼å¼ï¼š{"ç½‘ç«™å": [{"title": "...", "url": "..."}]}
        """
        logger.info(f"å¼€å§‹æŠ“å– {len(Config.TARGETS)} ä¸ªç½‘ç«™...")
        results = {}
        
        for site in Config.TARGETS:
            site_name = site['name']
            logger.info(f"æ­£åœ¨æŠ“å–: {site_name}")
            
            try:
                # è¯·æ±‚é¡µé¢
                response = self._fetch_with_retry(site['url'])
                if not response:
                    logger.error(f"âŒ {site_name} æŠ“å–å¤±è´¥")
                    results[site_name] = []
                    continue
                
                # è§£æHTML
                soup = BeautifulSoup(response.text, 'html.parser')
                items = soup.select(site['selector'])
                
                if not items:
                    logger.warning(f"âš ï¸  {site_name} æœªåŒ¹é…åˆ°å…¬å‘Š")
                    results[site_name] = []
                    continue
                
                # æå–å…¬å‘Šæ•°æ®
                announcements = []
                for item in items[:Config.MAX_ITEMS_PER_SITE]:
                    title = item.get_text(strip=True)
                    href = item.get('href', '')
                    
                    # å¤„ç†ç›¸å¯¹URL
                    if href and not href.startswith('http'):
                        url = site['base_url'] + href
                    else:
                        url = href
                    
                    # éªŒè¯æ•°æ®
                    if self._validate_announcement(title, url):
                        announcements.append({
                            "title": title,
                            "url": url
                        })
                
                results[site_name] = announcements
                logger.info(f"âœ“ {site_name} æŠ“å–æˆåŠŸï¼Œè·å¾— {len(announcements)} æ¡å…¬å‘Š")
                
            except Exception as e:
                logger.error(f"âŒ æŠ“å– {site_name} æ—¶å‡ºé”™: {e}")
                results[site_name] = []
        
        return results
    
    def load_history(self):
        """
        åŠ è½½å†å²è®°å½•
        
        Returns:
            å†å²æ•°æ®å­—å…¸
        """
        if not Config.HISTORY_FILE.exists():
            logger.info("å†å²æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°çš„")
            return {}
        
        try:
            with open(Config.HISTORY_FILE, 'r', encoding='utf-8') as f:
                history = json.load(f)
            logger.info(f"âœ“ åŠ è½½å†å²è®°å½•æˆåŠŸ")
            return history
        except Exception as e:
            logger.error(f"âŒ åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")
            return {}
    
    def save_history(self, data):
        """
        ä¿å­˜å†å²è®°å½•
        
        Args:
            data: è¦ä¿å­˜çš„æ•°æ®
        """
        try:
            with open(Config.HISTORY_FILE, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logger.info("âœ“ å†å²è®°å½•å·²æ›´æ–°")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")
    
    def find_new_announcements(self, current_data, history):
        """
        æ‰¾å‡ºæ–°å…¬å‘Š
        
        Args:
            current_data: å½“å‰æŠ“å–çš„æ•°æ®
            history: å†å²æ•°æ®
            
        Returns:
            æ–°å…¬å‘Šåˆ—è¡¨
        """
        new_updates = []
        
        for site_name, announcements in current_data.items():
            # è·å–å†å²æ ‡é¢˜
            old_titles = [item['title'] for item in history.get(site_name, [])]
            
            # æŸ¥æ‰¾æ–°å…¬å‘Š
            for item in announcements:
                if item['title'] not in old_titles:
                    new_updates.append({
                        'site': site_name,
                        'title': item['title'],
                        'url': item['url']
                    })
                    logger.info(f"ğŸ†• å‘ç°æ–°å…¬å‘Š: [{site_name}] {item['title'][:50]}...")
        
        return new_updates
    
    def send_email(self, new_updates):
        """
        å‘é€é‚®ä»¶é€šçŸ¥
        
        Args:
            new_updates: æ–°å…¬å‘Šåˆ—è¡¨
        """
        # æ ¼å¼åŒ–é‚®ä»¶å†…å®¹
        updates_text = []
        for update in new_updates:
            updates_text.append(
                f"ğŸ“Œ {update['site']}\n"
                f"æ ‡é¢˜: {update['title']}\n"
                f"åœ°å€: {update['url']}"
            )
        
        body = Config.EMAIL_TEMPLATE.format(updates="\n\n".join(updates_text))
        
        # åˆ›å»ºé‚®ä»¶
        msg = MIMEText(body, 'plain', 'utf-8')
        msg['Subject'] = Header(Config.EMAIL_SUBJECT, 'utf-8')
        msg['From'] = Config.SENDER_EMAIL
        msg['To'] = Config.RECEIVER_EMAIL
        
        # å‘é€é‚®ä»¶
        try:
            logger.info("æ­£åœ¨å‘é€é‚®ä»¶...")
            with smtplib.SMTP_SSL(Config.SMTP_SERVER, Config.SMTP_PORT) as server:
                server.login(Config.SENDER_EMAIL, Config.SENDER_PASSWORD)
                server.sendmail(
                    Config.SENDER_EMAIL,
                    [Config.RECEIVER_EMAIL],
                    msg.as_string()
                )
            logger.info("âœ“ é‚®ä»¶å‘é€æˆåŠŸï¼")
            return True
        except Exception as e:
            logger.error(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {e}")
            return False
    
    def run(self, dry_run=False):
        """
        è¿è¡Œç›‘æ§
        
        Args:
            dry_run: å¦‚æœä¸ºTrueï¼Œä¸å‘é€é‚®ä»¶ï¼Œåªæ˜¾ç¤ºå†…å®¹
        """
        logger.info("å¼€å§‹æ£€æŸ¥å®˜ç½‘æ›´æ–°...")
        
        # æŠ“å–å½“å‰æ•°æ®
        current_data = self.get_announcements()
        
        # åŠ è½½å†å²
        history = self.load_history()
        
        # æ‰¾å‡ºæ–°å…¬å‘Š
        new_updates = self.find_new_announcements(current_data, history)
        
        # æ›´æ–°å†å²è®°å½•
        self.save_history(current_data)
        
        # å¤„ç†ç»“æœ
        if new_updates:
            logger.info(f"ğŸ‰ æ£€æµ‹åˆ° {len(new_updates)} æ¡æ–°å…¬å‘Š")
            
            if dry_run:
                logger.info("ã€å¹²è¿è¡Œæ¨¡å¼ã€‘ä¸å‘é€é‚®ä»¶ï¼Œå†…å®¹å¦‚ä¸‹ï¼š")
                for update in new_updates:
                    print(f"\nğŸ“Œ {update['site']}")
                    print(f"æ ‡é¢˜: {update['title']}")
                    print(f"åœ°å€: {update['url']}")
            else:
                self.send_email(new_updates)
        else:
            logger.info("âœ… æš‚æ— æ–°å…¬å‘Š")
        
        logger.info("=" * 60)
        logger.info("æ£€æŸ¥å®Œæˆ")
        logger.info("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description='SNUå…¬å‘Šç›‘æ§ç³»ç»Ÿ - è‡ªåŠ¨ç›‘æ§é¦–å°”å¤§å­¦å®˜ç½‘å…¬å‘Š'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='å¹²è¿è¡Œæ¨¡å¼ï¼Œä¸å‘é€é‚®ä»¶ï¼Œåªæ˜¾ç¤ºæ–°å…¬å‘Šå†…å®¹'
    )
    args = parser.parse_args()
    
    try:
        notifier = SNUNotifier()
        notifier.run(dry_run=args.dry_run)
    except KeyboardInterrupt:
        logger.warning("\nâš ï¸  ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        logger.error(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        exit(1)


if __name__ == "__main__":
    main()
